---
title: "Talking with tact replication study: data analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Talking with tact
This is the code for data analysis of the "Talking with tact" replication study. 
Load all the necessary libraries
```{r}
library(tidyverse)
library(brms)
library(rstan)
# set cores to use to the total number of cores (minimally 4)
options(mc.cores = max(parallel::detectCores(), 4))
# save a compiled version of the Stan model file
rstan_options(auto_write = TRUE)
library(faintr)
# set a seed for random number generator
set.seed(123)
```

First, the data is read from a csv-file.
```{r}
d <- read.csv("results.csv")
d1 <- read.csv("results (1).csv")
d2 <- read.csv("results (2).csv")
d3 <- read.csv("results (3).csv")
d <- rbind(d, d1)
d <- rbind(d, d2)
d <- rbind(d, d3)

```

Take a first look at the data. 

```{r}
glimpse(d)
```

Select the data of interest: certain columns. Set the data types. Look at the data frame. 
We *do not* need all the additional info like age etc. 
We *need*: native languages, goal, utterance, *rating*(=inferred state), submission ID, item (scenario), time spent (for removing outliers)  

``` {r}
d <- select(d, c(trial_number, domain, goal, utterance, inferred_goal_state, languages))
# set data types: RT is int, goal & rating (?) & utterance should be factors
# utterance is a predictor which is scaled orinally! 
# factor utterance assigns the ordered levels to the diefferent utterances 
d <- mutate(d, goal = factor(goal), utterance = factor(utterance, levels=c("furchtbar", "schlecht", "okay", "gut", "hervorragend"), ordered=T), inferred_state = inferred_goal_state)
View(d)
```
Plot the data grouped by goals (nice, honest, mean) vs inferred state.
```{r}
# plots the dots , is  not very insightful
ggplot(d, aes(x=utterance, y=inferred_state, color=goal)) + geom_point()
```
Remove outliers: exclude participants where German was not a native language, and time spent was too long (2 minutes?)

Show means for each design cell: goal x utterance. 
```{r}
library(Rmisc)
#d <- filter(d, timeSpent <= 120000)
#excludes too many fore some reason
d <- filter(d, grepl("Deutsch", languages, ignore.case = T ))

# can we just use mean(rating), although it is an ordinally scaled parameter?
dmeans <- d %>% group_by(goal, utterance) %>% summarize(inferred_state=mean(inferred_state)) 
dm<- summarySE(d, measurevar = "inferred_state", groupvars = c("goal", "utterance"))
# plot graph 1 of the original paper Fig 3 .  
ggplot(dm, aes(x=utterance, y=inferred_state, color=goal)) + geom_point()+geom_line(aes(group=goal), size=0.5)+geom_errorbar(aes(ymin=inferred_state-ci, ymax=inferred_state+ci))

```
Fit the model: bayesian fixed-effects model for ordinal scale 
```{r}
model1 <- brm(inferred_state ~ mo(utterance)+goal+mo(utterance)*goal, d)
summary(model1)
marginal_effects(model1, "utterance:goal")

```
Check hypotheses:
- Draw posterior samples
- Inferred states for honest condition are higher than inferred states for nice condition for positive utterances
- Inferred states for nice condition are higher than inferred states for mean consition for positive utterances
- Inferred states for honest and nice conditions are equal for negative utterances
- Inferred states for mean condition are higher than for honest condition for negative utterances 
``` {r}
# posterior samples
post_samples <- posterior_samples(model1)%>% as_tibble
# Inferred states for honest condition are higher than inferred states for #nice condition for positive utterances
post_ehrlich_hervor <- post_samples$b_Intercept+post_samples$`simo_moutterance1[4]`
post_nett_hervor <- post_samples$b_Intercept+post_samples$b_goalnett+post_samples$`simo_moutterance:goalnett1[4]`
post_gemein_hervor <- post_samples$b_Intercept + post_samples$b_goalgemein + post_samples$`simo_moutterance:goalgemein1[4]`
post_ehrlich_schr <- post_samples$b_Intercept+post_samples$`simo_moutterance1[1]`
post_nett_schr <- post_samples$b_Intercept + post_samples$b_goalnett + post_samples$`simo_moutterance1[1]`
post_gemein_schr <- post_samples$b_Intercept+post_samples$b_goalgemein+post_samples$`simo_moutterance:goalgemein1[1]`

mean(mean(post_ehrlich_hervor)>mean(post_nett_hervor))
mean(mean(post_nett_hervor)>mean(post_gemein_hervor))
mean(mean(post_ehrlich_schr)==mean(post_nett_schr))
mean(mean(post_ehrlich_schr)<mean(post_gemein_schr))
```
Fit a model with random by-item efects
Check same hypotheses 
```{r}
model2 <- brm(inferred_state ~ mo(utterance)+goal+mo(utterance)*goal+(1|domain), d)
summary(model2)
```

#Conclusion 
